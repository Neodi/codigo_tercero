{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de librerías"
      ],
      "metadata": {
        "id": "aWcGXWlrB-yX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Q6ZVzlUsRQFf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### En caso de estar disponible se usa la gpu, si no se usa la cpu."
      ],
      "metadata": {
        "id": "wni-cFBaCGkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprueba si la GPU está disponible y utiliza CUDA si es posible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pFmlgQnxRY-g",
        "outputId": "af5e10d0-7e31-4b00-8a15-13af931391e7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformación y carga de datos CIFAR-10\n",
        "\n",
        "Transformación:\n",
        "- transform.Compose() combina varias transformaciones en una sola función para poder aplicarlas de forma secuencial.\n",
        "\n",
        "- ToTensor() combierte las imágenes a tensores y cambia e rango de valores de 0-255 a 0-1.\n",
        "\n",
        "- Normalize() normaliza los canales RGB de las imagenes (en este caso estableca las medias y desviaciones típicas a 0.5)\n",
        "\n",
        "Carga de datos:\n",
        "- torchvision.datasets.CIFAR10() carga el conjunto de datos.\n",
        "\n",
        "- .DataLoader() configura el batch size a 64 y mezcla los datos del train set. Usa 2 workers (2 subprocesos) para mejorar la velocidad de carga."
      ],
      "metadata": {
        "id": "8vSJKTJYC1Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para el conjunto de datos CIFAR-10\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Cargar los conjuntos de datos de entrenamiento y prueba\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Os5aopBcRY7b",
        "outputId": "e208d99c-aa59-4fa8-a1ad-f023eeabffb3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar un Modelo Preentrenado y Modificarlo para CIFAR-10\n",
        "\n",
        "#### Cargar el Modelo Preentrenado:\n",
        "- models.resnet18(): Carga una versión preentrenada de ResNet-18.\n",
        "\n",
        "#### Modificar la Capa de Salida:\n",
        "- num_ftrs = model.fc.in_features: Obtiene el número de características de entrada de la última capa lineal del modelo ResNet-18, necesitamos modificarla para que coincida con el número de clases en CIFAR-10.\n",
        "- model.fc = nn.Linear(num_ftrs, 10): reemplaza la ultima capa con una nueva que tiene 10 salidas.\n",
        "\n",
        "#### Mover el modelo a la GPU\n",
        "- model.to(device): Mueve el modelo a la GPU.\n",
        "\n"
      ],
      "metadata": {
        "id": "BwC1N6_DIscB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar un modelo preentrenado y modificarlo\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10) # 10 clases en CIFAR-10\n",
        "\n",
        "# Mover el modelo a la GPU\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "buWbZp1CRY32",
        "outputId": "2c545516-5954-4ae6-9f8f-7de3af5edad5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de Criterio de Pérdida y Optimizador\n",
        "\n",
        "#### Criterio de Pérdida:\n",
        "- criterion = nn.CrossEntropyLoss(): Define el criterio de pérdida como la entropía cruzada, utilizada para problemas de clasificación.\n",
        "\n",
        "#### Optimizador:\n",
        "- optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9): Configura el optimizador como el Descenso de Gradiente Estocástico (SGD). `lr` es la tasa de aprendizaje, y `momentum` es un término que ayuda a acelerar el SGD en la dirección correcta y amortiguar las oscilaciones. El alto momentum de 0.9 contribuye a que el optimizador mantenga la dirección en la que la pérdida decrece más rápidamente.\n"
      ],
      "metadata": {
        "id": "zfQnzScfLB9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir criterio de pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "4S_996DJRY0m"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aKfe4gOpsILh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bucle de entrenamiento\n",
        "\n",
        "-Durante cada época, el modelo se pone en modo de entrenamiento y procesa los datos en batches. Para cada batch, realiza una pasada hacia adelante generando predicciones, calcula la pérdida con respecto a las verdaderas etiquetas, realiza una pasada hacia atrás para calcular los gradientes, y luego ajusta los pesos con un paso de optimización"
      ],
      "metadata": {
        "id": "5vkCCD3qjPFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15 # Define el número de épocas\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Poner el modelo en modo de entrenamiento\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device) # Mover los datos a la GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Época {epoch + 1}, Pérdida: {running_loss / len(trainloader):.3f}')\n",
        "\n",
        "\n",
        "\n",
        "print('Entrenamiento finalizado')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X-G-AWaWRYxa",
        "outputId": "bbc6f11a-e29b-4e7c-961f-efb630c6e387"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Pérdida: 1.034\n",
            "Época 2, Pérdida: 0.631\n",
            "Época 3, Pérdida: 0.477\n",
            "Época 4, Pérdida: 0.372\n",
            "Época 5, Pérdida: 0.287\n",
            "Época 6, Pérdida: 0.228\n",
            "Época 7, Pérdida: 0.178\n",
            "Época 8, Pérdida: 0.137\n",
            "Época 9, Pérdida: 0.113\n",
            "Época 10, Pérdida: 0.097\n",
            "Época 11, Pérdida: 0.086\n",
            "Época 12, Pérdida: 0.079\n",
            "Época 13, Pérdida: 0.068\n",
            "Época 14, Pérdida: 0.058\n",
            "Época 15, Pérdida: 0.060\n",
            "Entrenamiento finalizado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se comprueba la precisión del modelo con el conjunto de test\n"
      ],
      "metadata": {
        "id": "PRE4hcQ8lh_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Precisión del modelo en el conjunto de datos de prueba CIFAR-10: {100 * correct // total}%')"
      ],
      "metadata": {
        "id": "6ncImZNRRYuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c02ccee8-3ab2-4786-bd32-9de6f3a8ed5a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo en el conjunto de datos de prueba CIFAR-10: 79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mejorar Modelo"
      ],
      "metadata": {
        "id": "fvY_FB-nvTFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Configuración de dispositivo (GPU si está disponible)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "YLxrBCwqRYZf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Igual que antes pero aplicando algo de data augmentation con RandomHorizontalflip y Rndom Rotation (10 es el máximo de grados que puede rotar una imagen)"
      ],
      "metadata": {
        "id": "GktWC8n5AhZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para el conjunto de datos CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Cargar los conjuntos de datos de entrenamiento y prueba\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data_2', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data_2', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en subconjuntos de entrenamiento y validación\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = len(trainset) - train_size\n",
        "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YtG8WGz6RYWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22cf877-4036-4872-d905-a6fcd3e75038"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_2/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 106008470.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data_2/cifar-10-python.tar.gz to ./data_2\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### En vez de usar resnet 18 esamos el 34 y añadimos dropout\n"
      ],
      "metadata": {
        "id": "fuijFk6IAf60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo\n",
        "model = models.resnet34(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "\n",
        "# Añadir dropout a la capa final\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(num_ftrs, 10)  # 10 clases para CIFAR-10\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Criterio de pérdida y optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtAKL46txY3T",
        "outputId": "452cd916-55b7-4015-aacf-ca6c13cb3577"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 70.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se añaden mas épocas, he puesto 100(claramente no hacen falta tantas, de hecho llega a 83% en la época 45)."
      ],
      "metadata": {
        "id": "36iyg7bwCHIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Entrenamiento\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Época {epoch + 1}, Pérdida de Entrenamiento: {running_loss / len(trainloader)}, Pérdida de Validación: {val_loss / len(valloader)}, Precisión de Validación: {100 * correct / total}%')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVel7bNJxYv3",
        "outputId": "7bbe9f18-2e5d-4de6-c344-4e2d45e64975"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Pérdida de Entrenamiento: 1.2816181645393372, Pérdida de Validación: 0.865786459795229, Precisión de Validación: 69.6%\n",
            "Época 2, Pérdida de Entrenamiento: 0.8284113910198212, Pérdida de Validación: 0.7187041763667088, Precisión de Validación: 75.24%\n",
            "Época 3, Pérdida de Entrenamiento: 0.6968674880504608, Pérdida de Validación: 0.6596883548672792, Precisión de Validación: 76.96%\n",
            "Época 4, Pérdida de Entrenamiento: 0.6156878041744233, Pérdida de Validación: 0.6083787544897408, Precisión de Validación: 78.62%\n",
            "Época 5, Pérdida de Entrenamiento: 0.5580404947042465, Pérdida de Validación: 0.6120230948469442, Precisión de Validación: 78.67%\n",
            "Época 6, Pérdida de Entrenamiento: 0.5112025663375854, Pérdida de Validación: 0.5788823654697199, Precisión de Validación: 80.17%\n",
            "Época 7, Pérdida de Entrenamiento: 0.47090019094944, Pérdida de Validación: 0.580899579509808, Precisión de Validación: 80.17%\n",
            "Época 8, Pérdida de Entrenamiento: 0.43528888432979584, Pérdida de Validación: 0.5674924811550007, Precisión de Validación: 80.63%\n",
            "Época 9, Pérdida de Entrenamiento: 0.40315507061481476, Pérdida de Validación: 0.5523174653767021, Precisión de Validación: 81.22%\n",
            "Época 10, Pérdida de Entrenamiento: 0.3791414156675339, Pérdida de Validación: 0.5591388911388482, Precisión de Validación: 81.47%\n",
            "Época 11, Pérdida de Entrenamiento: 0.35028048914670945, Pérdida de Validación: 0.5644324229211565, Precisión de Validación: 80.98%\n",
            "Época 12, Pérdida de Entrenamiento: 0.3273379083812237, Pérdida de Validación: 0.5751521589270063, Precisión de Validación: 81.27%\n",
            "Época 13, Pérdida de Entrenamiento: 0.305217151927948, Pérdida de Validación: 0.5807885842718137, Precisión de Validación: 81.51%\n",
            "Época 14, Pérdida de Entrenamiento: 0.28835019820928576, Pérdida de Validación: 0.5910490763605021, Precisión de Validación: 81.11%\n",
            "Época 15, Pérdida de Entrenamiento: 0.2759948756575584, Pérdida de Validación: 0.5895606920977307, Precisión de Validación: 81.39%\n",
            "Época 16, Pérdida de Entrenamiento: 0.25667227692604067, Pérdida de Validación: 0.5972583580548596, Precisión de Validación: 81.75%\n",
            "Época 17, Pérdida de Entrenamiento: 0.23797228573560714, Pérdida de Validación: 0.5923486015978893, Precisión de Validación: 82.26%\n",
            "Época 18, Pérdida de Entrenamiento: 0.2206595583498478, Pérdida de Validación: 0.6016866203136505, Precisión de Validación: 82.05%\n",
            "Época 19, Pérdida de Entrenamiento: 0.2190454529762268, Pérdida de Validación: 0.5842918061716541, Precisión de Validación: 82.25%\n",
            "Época 20, Pérdida de Entrenamiento: 0.2027047119319439, Pérdida de Validación: 0.6098287806009791, Precisión de Validación: 82.14%\n",
            "Época 21, Pérdida de Entrenamiento: 0.1843450759768486, Pérdida de Validación: 0.6341530939765797, Precisión de Validación: 82.12%\n",
            "Época 22, Pérdida de Entrenamiento: 0.17853839466273785, Pérdida de Validación: 0.6416574149944221, Precisión de Validación: 82.12%\n",
            "Época 23, Pérdida de Entrenamiento: 0.17363472552597523, Pérdida de Validación: 0.624179543867992, Precisión de Validación: 82.44%\n",
            "Época 24, Pérdida de Entrenamiento: 0.16180518856048584, Pérdida de Validación: 0.6666458628739521, Precisión de Validación: 81.76%\n",
            "Época 25, Pérdida de Entrenamiento: 0.1457162114173174, Pérdida de Validación: 0.6348478805487323, Precisión de Validación: 83.0%\n",
            "Época 26, Pérdida de Entrenamiento: 0.14542306432724, Pérdida de Validación: 0.6566977975474801, Precisión de Validación: 81.99%\n",
            "Época 27, Pérdida de Entrenamiento: 0.13574618054926396, Pérdida de Validación: 0.6612780178618279, Precisión de Validación: 82.9%\n",
            "Época 28, Pérdida de Entrenamiento: 0.1321363686516881, Pérdida de Validación: 0.70192839100862, Precisión de Validación: 81.84%\n",
            "Época 29, Pérdida de Entrenamiento: 0.12353879631161689, Pérdida de Validación: 0.7068683032871811, Precisión de Validación: 82.04%\n",
            "Época 30, Pérdida de Entrenamiento: 0.118155947509408, Pérdida de Validación: 0.6792771263866667, Precisión de Validación: 82.84%\n",
            "Época 31, Pérdida de Entrenamiento: 0.11128800459206105, Pérdida de Validación: 0.6823070267583154, Precisión de Validación: 82.66%\n",
            "Época 32, Pérdida de Entrenamiento: 0.10882874724417925, Pérdida de Validación: 0.6956198974779457, Precisión de Validación: 82.61%\n",
            "Época 33, Pérdida de Entrenamiento: 0.10788391347452998, Pérdida de Validación: 0.7044729909319787, Precisión de Validación: 82.67%\n",
            "Época 34, Pérdida de Entrenamiento: 0.09703406999856233, Pérdida de Validación: 0.7028038017689042, Precisión de Validación: 82.69%\n",
            "Época 35, Pérdida de Entrenamiento: 0.0954205733180046, Pérdida de Validación: 0.7412422868856199, Precisión de Validación: 81.91%\n",
            "Época 36, Pérdida de Entrenamiento: 0.09551787529438734, Pérdida de Validación: 0.706037069676788, Precisión de Validación: 82.79%\n",
            "Época 37, Pérdida de Entrenamiento: 0.08655275498107076, Pérdida de Validación: 0.7440089971586398, Precisión de Validación: 82.68%\n",
            "Época 38, Pérdida de Entrenamiento: 0.084867331456393, Pérdida de Validación: 0.7140884570255401, Precisión de Validación: 82.79%\n",
            "Época 39, Pérdida de Entrenamiento: 0.08226611150950193, Pérdida de Validación: 0.7316169643857676, Precisión de Validación: 82.58%\n",
            "Época 40, Pérdida de Entrenamiento: 0.08040054732859135, Pérdida de Validación: 0.7585606273192509, Precisión de Validación: 82.63%\n",
            "Época 41, Pérdida de Entrenamiento: 0.0748439659755677, Pérdida de Validación: 0.7617023287305407, Precisión de Validación: 82.26%\n",
            "Época 42, Pérdida de Entrenamiento: 0.0696313225928694, Pérdida de Validación: 0.745329830487063, Precisión de Validación: 82.78%\n",
            "Época 43, Pérdida de Entrenamiento: 0.07089386128969491, Pérdida de Validación: 0.7359770560150694, Precisión de Validación: 82.94%\n",
            "Época 44, Pérdida de Entrenamiento: 0.06794105691052973, Pérdida de Validación: 0.7645842290607987, Precisión de Validación: 82.84%\n",
            "Época 45, Pérdida de Entrenamiento: 0.06566364174671471, Pérdida de Validación: 0.753246930564285, Precisión de Validación: 83.16%\n",
            "Época 46, Pérdida de Entrenamiento: 0.06213050222918391, Pérdida de Validación: 0.7595935907143696, Precisión de Validación: 83.15%\n",
            "Época 47, Pérdida de Entrenamiento: 0.05858122681342065, Pérdida de Validación: 0.7807861112864913, Precisión de Validación: 83.02%\n",
            "Época 48, Pérdida de Entrenamiento: 0.06296932253390551, Pérdida de Validación: 0.7592541371371336, Precisión de Validación: 83.08%\n",
            "Época 49, Pérdida de Entrenamiento: 0.059297894174605605, Pérdida de Validación: 0.755159515863771, Precisión de Validación: 83.35%\n",
            "Época 50, Pérdida de Entrenamiento: 0.06134654622450471, Pérdida de Validación: 0.7351847669691037, Precisión de Validación: 83.3%\n",
            "Época 51, Pérdida de Entrenamiento: 0.0565259028043598, Pérdida de Validación: 0.7621708731078038, Precisión de Validación: 82.66%\n",
            "Época 52, Pérdida de Entrenamiento: 0.05558826155588031, Pérdida de Validación: 0.7746137006647268, Precisión de Validación: 82.64%\n",
            "Época 53, Pérdida de Entrenamiento: 0.05149112268909812, Pérdida de Validación: 0.7536129248654766, Precisión de Validación: 83.37%\n",
            "Época 54, Pérdida de Entrenamiento: 0.048763965717703105, Pérdida de Validación: 0.8019941272154735, Precisión de Validación: 82.59%\n",
            "Época 55, Pérdida de Entrenamiento: 0.05327431376241148, Pérdida de Validación: 0.7988115091612384, Precisión de Validación: 82.71%\n",
            "Época 56, Pérdida de Entrenamiento: 0.048077031788602474, Pérdida de Validación: 0.7905247971700256, Precisión de Validación: 83.07%\n",
            "Época 57, Pérdida de Entrenamiento: 0.04462644690349698, Pérdida de Validación: 0.7791293922123635, Precisión de Validación: 83.17%\n",
            "Época 58, Pérdida de Entrenamiento: 0.044417738312855365, Pérdida de Validación: 0.7970210124922407, Precisión de Validación: 82.61%\n",
            "Época 59, Pérdida de Entrenamiento: 0.042120253819413485, Pérdida de Validación: 0.8005644836623198, Precisión de Validación: 83.01%\n",
            "Época 60, Pérdida de Entrenamiento: 0.04527778702285141, Pérdida de Validación: 0.8011211141659196, Precisión de Validación: 83.31%\n",
            "Época 61, Pérdida de Entrenamiento: 0.04270954130645841, Pérdida de Validación: 0.8241775409810862, Precisión de Validación: 83.07%\n",
            "Época 62, Pérdida de Entrenamiento: 0.04601784253688529, Pérdida de Validación: 0.7881426140191449, Precisión de Validación: 83.13%\n",
            "Época 63, Pérdida de Entrenamiento: 0.042733141018264, Pérdida de Validación: 0.8150116106507125, Precisión de Validación: 82.75%\n",
            "Época 64, Pérdida de Entrenamiento: 0.04227029077960178, Pérdida de Validación: 0.8028204676451957, Precisión de Validación: 83.24%\n",
            "Época 65, Pérdida de Entrenamiento: 0.03801491963900626, Pérdida de Validación: 0.8292007914204507, Precisión de Validación: 83.39%\n",
            "Época 66, Pérdida de Entrenamiento: 0.03804904211359099, Pérdida de Validación: 0.8233287099060739, Precisión de Validación: 83.23%\n",
            "Época 67, Pérdida de Entrenamiento: 0.03726614969186485, Pérdida de Validación: 0.8455499517879669, Precisión de Validación: 82.92%\n",
            "Época 68, Pérdida de Entrenamiento: 0.03674242315255106, Pérdida de Validación: 0.7951067988849749, Precisión de Validación: 83.65%\n",
            "Época 69, Pérdida de Entrenamiento: 0.03501587657518685, Pérdida de Validación: 0.8574707113253842, Precisión de Validación: 83.05%\n",
            "Época 70, Pérdida de Entrenamiento: 0.03461162383314222, Pérdida de Validación: 0.8311872673072632, Precisión de Validación: 83.02%\n",
            "Época 71, Pérdida de Entrenamiento: 0.03388525401819498, Pérdida de Validación: 0.8340661083437075, Precisión de Validación: 83.26%\n",
            "Época 72, Pérdida de Entrenamiento: 0.03150938242273405, Pérdida de Validación: 0.8597664017776016, Precisión de Validación: 82.89%\n",
            "Época 73, Pérdida de Entrenamiento: 0.02904826406268403, Pérdida de Validación: 0.8321703438925895, Precisión de Validación: 82.88%\n",
            "Época 74, Pérdida de Entrenamiento: 0.031604334856197236, Pérdida de Validación: 0.8226992053211115, Precisión de Validación: 83.51%\n",
            "Época 75, Pérdida de Entrenamiento: 0.03334231213098392, Pérdida de Validación: 0.8210777276830309, Precisión de Validación: 83.45%\n",
            "Época 76, Pérdida de Entrenamiento: 0.030566946990229188, Pérdida de Validación: 0.8503854900218879, Precisión de Validación: 83.5%\n",
            "Época 77, Pérdida de Entrenamiento: 0.03173885249868035, Pérdida de Validación: 0.8593253018749747, Precisión de Validación: 83.01%\n",
            "Época 78, Pérdida de Entrenamiento: 0.029302109446749092, Pérdida de Validación: 0.8579848625098064, Precisión de Validación: 83.46%\n",
            "Época 79, Pérdida de Entrenamiento: 0.032226300483383236, Pérdida de Validación: 0.83920216674258, Precisión de Validación: 83.02%\n",
            "Época 80, Pérdida de Entrenamiento: 0.03000664663212374, Pérdida de Validación: 0.8324989003550475, Precisión de Validación: 83.72%\n",
            "Época 81, Pérdida de Entrenamiento: 0.02789437714824453, Pérdida de Validación: 0.8337992456308596, Precisión de Validación: 83.39%\n",
            "Época 82, Pérdida de Entrenamiento: 0.02856495214840397, Pérdida de Validación: 0.8372254842405866, Precisión de Validación: 83.33%\n",
            "Época 83, Pérdida de Entrenamiento: 0.027009582022437827, Pérdida de Validación: 0.8569547635544638, Precisión de Validación: 82.99%\n",
            "Época 84, Pérdida de Entrenamiento: 0.024991821194114163, Pérdida de Validación: 0.8406291570822904, Precisión de Validación: 83.86%\n",
            "Época 85, Pérdida de Entrenamiento: 0.02389010264086537, Pérdida de Validación: 0.872542840659998, Precisión de Validación: 83.35%\n",
            "Época 86, Pérdida de Entrenamiento: 0.024590892298240213, Pérdida de Validación: 0.8783473277547557, Precisión de Validación: 83.28%\n",
            "Época 87, Pérdida de Entrenamiento: 0.02654961482351646, Pérdida de Validación: 0.8512028582916138, Precisión de Validación: 83.46%\n",
            "Época 88, Pérdida de Entrenamiento: 0.02168171633090824, Pérdida de Validación: 0.8819187155384927, Precisión de Validación: 83.4%\n",
            "Época 89, Pérdida de Entrenamiento: 0.0251024855916854, Pérdida de Validación: 0.8526555680830008, Precisión de Validación: 83.7%\n",
            "Época 90, Pérdida de Entrenamiento: 0.027431673267157747, Pérdida de Validación: 0.8690820268005323, Precisión de Validación: 83.24%\n",
            "Época 91, Pérdida de Entrenamiento: 0.02333302778424695, Pérdida de Validación: 0.866089639485262, Precisión de Validación: 83.36%\n",
            "Época 92, Pérdida de Entrenamiento: 0.02353565349271521, Pérdida de Validación: 0.8514417793340744, Precisión de Validación: 83.46%\n",
            "Época 93, Pérdida de Entrenamiento: 0.023588991404743864, Pérdida de Validación: 0.8857896627893873, Precisión de Validación: 83.25%\n",
            "Época 94, Pérdida de Entrenamiento: 0.022618609686708077, Pérdida de Validación: 0.8728809782843681, Precisión de Validación: 83.01%\n",
            "Época 95, Pérdida de Entrenamiento: 0.02221600018092431, Pérdida de Validación: 0.9162442970807385, Precisión de Validación: 83.06%\n",
            "Época 96, Pérdida de Entrenamiento: 0.0192888249916723, Pérdida de Validación: 0.85127675191612, Precisión de Validación: 83.32%\n",
            "Época 97, Pérdida de Entrenamiento: 0.016272427391749805, Pérdida de Validación: 0.9099587724087345, Precisión de Validación: 83.15%\n",
            "Época 98, Pérdida de Entrenamiento: 0.01906826557100285, Pérdida de Validación: 0.8662975655429682, Precisión de Validación: 83.72%\n",
            "Época 99, Pérdida de Entrenamiento: 0.020006740600569173, Pérdida de Validación: 0.8854805616436491, Precisión de Validación: 83.71%\n",
            "Época 100, Pérdida de Entrenamiento: 0.024382338631525637, Pérdida de Validación: 0.8904949160897808, Precisión de Validación: 83.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Precisión del modelo en el conjunto de datos de prueba CIFAR-10: {100 * correct // total}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lPrv8puxYnz",
        "outputId": "cb2b541c-bd02-4830-dd9f-11927997b017"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo en el conjunto de datos de prueba CIFAR-10: 83%\n"
          ]
        }
      ]
    }
  ]
}